---
title: "PS3 Solutions"
author: "Teaching Staff"
date: "February 2023"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
```

## Q1

First a regression table helper function to clean up the summary tables. 

```{r}
regTable = function(model){
  m = summary(model)
  tidydf = data.frame(terms = names(m[["coefficients"]][,1]),
                      estimates = round(m[["coefficients"]][,1],4),
                      std.error = m[["coefficients"]][,2],
                      statistic = m[["coefficients"]][,3],
                      p.value = m[["coefficients"]][,4],
                      row.names = NULL)
  
  ## Round the numeric columns to 4 digits
  tidydf[, 2:ncol(tidydf)] = apply(tidydf[, 2:ncol(tidydf)], 
                                      2, 
                                      function(x) round(x, 4)
                                      )
  return(tidydf)
}
```

```{r}
set.seed(123)
x = rexp(1500, rate = 2)
```

### 1 

```{r}
boot_univariate = function(datvec, statint, B, alpha){
  out = vector(mode = "logical", length = B)
  for(i in 1:B){
    out[i] = statint(sample(datvec, replace = T))
  }
  conf.out = quantile(out, probs = c(alpha/2, 1-alpha/2))
  return(conf.out)
}

```

### 2 
```{r, cache = T}
boot_univariate(x, median, 10000, 0.05)
```

The produces a 95% bootstrap confidence interval for the median of the variable represented by x.

### Bonus 

```{r, cache= T}
iqr = function(x){
  return(quantile(x, probs = .75) - quantile(x, probs = .25))
}
boot_univariate(x, iqr, 10000, 0.05)
```

## Q2

### 1

```{r}
ca = read.csv("ca2006.csv")
```

### 2 

```{r, message=F, warning = F}
plot = ca |>
  ggplot(aes(dem_pres_2004, prop_d))+
  geom_point()+
  labs(x = "% Kerry Votes",
       y = "% Dem Votes (2006)",
       title = "Democratic Vote Share by County (2004-2006)")+
  theme_bw()+
  ylim(0,1)+
  xlim(0,1)
plot
```

### 3 

```{r, message = F, warning = F}
reg = lm(prop_d ~ dem_pres_2004, data = ca)
regTable(reg)
```

```{r, message = F, warning = F}
plot + geom_smooth(method = "lm", se = F)
```

### 4 
```{r}
my_predict = function(coefs, newdata, ols = TRUE){
  if(ols == TRUE){
    ## Linear Model prediction 
    prediction = sum(coefs%*%newdata)
    return(unname(prediction))
  }else{
    ## Logit Model prediction 
    betas = unname(coefs) %*% newdata
    odds = 1/ (1 + exp(-betas))
    return(odds)
  }
}

my_predict(reg$coefficients, newdata = c(1, 0.5))
```

### 5 and 6 

```{r}
mreg = lm(prop_d ~ dem_pres_2004 + dem_pres_2000 + dem_inc,
          data = ca)

my_predict(mreg$coefficients, 
           newdata = c(1,0.5, 0.5, 1), 
           ols = TRUE)
```

### 7 

```{r}
boot_reg = function(df, N = 53, B = 10000, alpha = 0.05){
  set.seed(pi)
  simple = vector(mode = "logical", length = B)
  multi = vector(mode = "logical", length = B)
  for(i in 1:B){
    dat = df[sample.int(nrow(df), 53, replace = T),]
    simple[i] = my_predict(lm(prop_d ~ dem_pres_2004, 
                              data = dat)$coefficients,
                           newdata = c(1,0.5))
    multi[i] = my_predict(lm(prop_d ~ dem_pres_2004 + 
                               dem_pres_2000 + dem_inc,
                             data = dat)$coefficients, 
                          newdata = c(1,0.5,0.5,1))
  }
  sci = quantile(simple, probs = c(alpha/2, 1-alpha/2))
  mci = quantile(multi, probs = c(alpha/2, 1-alpha/2))
  return(list(simple = simple, multi = multi,
              simple_ci = sci, multi_ci = mci))
}
```

### 8 

```{r, cache = T}
results = boot_reg(df = ca)
```

```{r, echo = F}
knitr::kable(rbind(results$simple_ci, results$multi_ci))
```

```{r, warning=F, message = F}
out = data.frame(id = c(rep("bivariate", 10000), 
                          rep("multi", 10000)),
                   result = c(results$simple, 
                               results$multi))
```


```{r}
out |>
  ggplot(aes(result))+
  geom_histogram(bins = 50)+
  facet_wrap(~id, scales = "free_x")
```

### 9 

```{r}
mean(results$simple > .5)
mean(results$multi > .5)
```

## Q3 

### 1 and 2 

```{r}
clinton = read.csv("vote92.csv")
mean(clinton$clintonvote)
```


### 3 

```{r}
logit = glm(clintonvote ~ dem + female + clintondist, data = clinton,
            family = "binomial")
regTable(logit)
```

### 4 and 5 

```{r}
## see my_predict() function definition 
my_predict(logit$coefficients, newdata = c(1,1,1,1), ols = FALSE)
```

### 6 

```{r, message = F, warning = F}
ols = lm(clintonvote ~ dem + female + clintondist, data = clinton)
ols.preds = vector(mode = "logical", nrow(clinton))
logit.preds = vector(mode = "logical", nrow(clinton))

for(i in 1:nrow(clinton)){
  newdata = newdata = c(1, as.numeric(clinton[i,c(2:4)]))
  ols.preds[i] = my_predict(ols$coefficients, newdata, ols = TRUE)
  logit.preds[i] = my_predict(logit$coefficients, newdata, ols = FALSE)
}
```

```{r}
data.frame(ols = ols.preds, logit = logit.preds) |>
  ggplot(aes(logit, ols))+
  geom_point()+
  geom_abline(intercept = 0,slope = 1)+
  theme_bw()
```

### Bonus 
```{r, message = F, warning = F}
bins = cut(logit.preds, breaks = seq(0,1,.1), right = FALSE,
           labels = c(1:10))
bonusDat = data.frame(preds = logit.preds, bins = bins)
mean_prob = aggregate(bonusDat$preds, by = list(bins), FUN=mean)
posi_prob = aggregate(clinton$clintonvote, by = list(bins), FUN=mean)

data.frame(mean_prob = mean_prob$x, posi_prob = posi_prob$x) |>
  ggplot(aes(mean_prob, posi_prob))+
  geom_point()+
  geom_line()+
  geom_abline(intercept = 0, slope = 1)+
  theme_bw()+
  labs(x = "Mean Predicted Probabilities",
       y = "Actual Proportion of Positives")

```